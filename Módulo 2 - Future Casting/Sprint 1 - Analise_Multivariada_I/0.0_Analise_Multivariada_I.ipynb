{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ANÁLISE MULTIVARIADA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Análise Fatorial Exploratória\n",
    "\n",
    "A AFE tem o propósito de reduzir a dimensionalidade dos dados, ou seja, reduzir o número de variáveis para simplificar seu entendimento. Porém, existe um _tradeoff_ entre simplificação e precisão. Ao simplificar a análise dos dados, perde-se também parte da informação trazida por eles. \\n\n",
    "\n",
    " A idea geral é encontrar variáveis latentes (os fatores), que expliquem em grande parte aa variância das variáveis originais. Por exemplo, um dataset pode conter as variáveis: venda_sorvetes, venda_protetor_solar e venda_agasalho. Essas variáveis podem ser explicadas por um fator: **temperatura**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Análise Fatorial Confirmatória\n",
    "\n",
    "Enquanto a AFE busca identificar os fatores (ou variáveis latentes) em um dataset, a AFC parte do pressuposto de que os fatores são conhecidos e busca confirmar se os dados de fato se encaixam nesse modelo. Isso é aplicável quando:\n",
    "- A) A AFE já foi realizada\n",
    "- B) Os dados são familiares e pode-se intuir os fatores\n",
    "- C) Os fatores são predefinidos por motivos alheios à análise e precisam ser seguidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## *ACP - Análise de Componentes Principais vs AFE - Análise Fatorial Exploratória\n",
    "\n",
    "PCA NÃO faz parte da Análise Fatorial Exploratória (EFA). São técnicas distintas usadas para propósitos diferentes no campo da estatística multivariada.\n",
    "\n",
    "PCA é uma técnica de redução de dimensionalidade que visa transformar as variáveis originais em um novo conjunto de componentes ortogonais, conhecidos como componentes principais, que capturam a máxima variância nos dados. É comumente usado para reduzir o número de dimensões nos dados enquanto mantém a maior parte das informações importantes.\n",
    "\n",
    "Por outro lado, a Análise Fatorial Exploratória (EFA) é um método estatístico usado para descobrir fatores latentes subjacentes que explicam as correlações entre variáveis observadas. É comumente usado em ciências sociais e psicologia para entender a estrutura das relações entre variáveis e identificar fatores comuns que contribuem para padrões observados.\n",
    "\n",
    "Embora tanto o PCA quanto a EFA lidem com a redução de dimensões, eles têm objetivos e pressupostos diferentes. O PCA concentra-se em explicar a variância nos dados, enquanto a EFA tem como objetivo identificar fatores subjacentes que explicam as correlações entre as variáveis observadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Passo a passo da AFE em Python\n",
    "\n",
    "1) Carregar os dados\n",
    "2) Tratar os dados (A necessidade de cada subitem deve ser considerada caso a caso)\n",
    "2.1) Tratar dados faltantes\n",
    "2.2) Tratar dados categóricos\n",
    "2.3) Eliminar colunas irrelevantes\n",
    "2.4) Padronizar os dados\n",
    "3) Gerar matriz de correlações E/OU o mapa de calor\n",
    "4) Confirmar a aplicabilidade da AFE\n",
    "4.1) Teste de esfericidade de Bartlett\n",
    "Resultado deve rejeitar H0 (p_valor < alfa)\n",
    "4.2) Teste de Kaiser-Meyer-Olkin (KMO)\n",
    "Resultado deve ser maior que o mínimo aceitável (0.5, nos exercícios do curso)\n",
    "5) Aplicar a AFE\n",
    "5.1) Instanciar objeto da classe FactorAnalyzer\n",
    "5.2) Obter os autovalores (eigenvalues)\n",
    "5.3) Selecionar os fatores com autovalores >=1\n",
    "6) Gerar Scree Plot\n",
    "7) Calcular as variâncias explicadas\n",
    "7.1) Variância total de cada fator\n",
    "7.2) Variância % de cada fator\n",
    "7.3) Variância % acumulada dos fatores\n",
    "8) Gerar a rotação dos fatores\n",
    "8.1) Instanciar o FactorAnalyzer com o parâmetro rotation='varimax'\n",
    "8.2) Obter as cargas fatoriais\n",
    "8.3) Gerar matriz das cargas fatoriais\n",
    "9) Interpretar os fatores\n",
    "10) Dar nomes aos fatores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae54d123",
   "metadata": {},
   "source": [
    "\n",
    "# Regressão Linear\n",
    "\n",
    "A regressão linear é uma técnica que busca modelar a relação entre duas ou mais variáveis. Uma variável é considerada dependente e as outras, independentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710d05a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Exemplo\n",
    "\n",
    "Pense em um conjunto de dados 'boston' que contém informações sobre diferentes casas em Boston. Uma regressão linear pode ser usada para prever o preço das casas com base em características como o número médio de quartos por habitação.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8feeabd",
   "metadata": {},
   "source": [
    "\n",
    "## Interpretação dos Resultados\n",
    "\n",
    "Os coeficientes de regressão representam a mudança na variável dependente para cada unidade de mudança na variável independente. Também podemos calcular o erro quadrático médio (RMSE) para avaliar o desempenho do modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e787a5b9",
   "metadata": {},
   "source": [
    "\n",
    "## Pressupostos da Regressão Linear\n",
    "\n",
    "A regressão linear faz várias suposições:\n",
    "\n",
    "1. Linearidade: A relação entre as variáveis é linear.\n",
    "2. Independência dos erros: Os erros são independentes entre si.\n",
    "3. Homocedasticidade: A variância dos erros é constante.\n",
    "4. Normalidade dos erros: Os erros são normalmente distribuídos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ef8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Verificando os Pressupostos\n",
    "\n",
    "Os pressupostos da regressão linear podem ser verificados visualmente usando gráficos residuais, gráficos Q-Q e testes estatísticos, como o teste de Durbin-Watson para autocorrelação.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918a2dd3",
   "metadata": {},
   "source": [
    "\n",
    "## Problemas Comuns e Soluções\n",
    "\n",
    "1. **Multicolinearidade**: A multicolinearidade ocorre quando duas ou mais variáveis independentes estão altamente correlacionadas entre si. Pode ser detectada com o fator de inflação da variância (VIF) e tratada removendo variáveis ou usando técnicas de regularização.\n",
    "\n",
    "2. **Autocorrelação**: A autocorrelação ocorre quando os erros não são independentes entre si. Pode ser detectada com o teste de Durbin-Watson e tratada usando técnicas de modelagem de séries temporais.\n",
    "\n",
    "3. **Heteroscedasticidade**: A heteroscedasticidade ocorre quando a variância dos erros não é constante. Pode ser visualizada em um gráfico de resíduos versus valores ajustados e tratada transformando a variável dependente ou usando técnicas de modelagem mais robustas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae54d123",
   "metadata": {},
   "source": [
    "\n",
    "# Regressão Linear\n",
    "\n",
    "A regressão linear é uma técnica que busca modelar a relação entre duas ou mais variáveis. Uma variável é considerada dependente e as outras, independentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710d05a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Exemplo\n",
    "\n",
    "Pense em um conjunto de dados 'boston' que contém informações sobre diferentes casas em Boston. Uma regressão linear pode ser usada para prever o preço das casas com base em características como o número médio de quartos por habitação.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8feeabd",
   "metadata": {},
   "source": [
    "\n",
    "## Interpretação dos Resultados\n",
    "\n",
    "Os coeficientes de regressão representam a mudança na variável dependente para cada unidade de mudança na variável independente. Também podemos calcular o erro quadrático médio (RMSE) para avaliar o desempenho do modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e787a5b9",
   "metadata": {},
   "source": [
    "\n",
    "## Pressupostos da Regressão Linear\n",
    "\n",
    "A regressão linear faz várias suposições:\n",
    "\n",
    "1. Linearidade: A relação entre as variáveis é linear.\n",
    "2. Independência dos erros: Os erros são independentes entre si.\n",
    "3. Homocedasticidade: A variância dos erros é constante.\n",
    "4. Normalidade dos erros: Os erros são normalmente distribuídos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ef8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Verificando os Pressupostos\n",
    "\n",
    "Os pressupostos da regressão linear podem ser verificados visualmente usando gráficos residuais, gráficos Q-Q e testes estatísticos, como o teste de Durbin-Watson para autocorrelação.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918a2dd3",
   "metadata": {},
   "source": [
    "\n",
    "## Problemas Comuns e Soluções\n",
    "\n",
    "1. **Multicolinearidade**: A multicolinearidade ocorre quando duas ou mais variáveis independentes estão altamente correlacionadas entre si. Pode ser detectada com o fator de inflação da variância (VIF) e tratada removendo variáveis ou usando técnicas de regularização.\n",
    "\n",
    "2. **Autocorrelação**: A autocorrelação ocorre quando os erros não são independentes entre si. Pode ser detectada com o teste de Durbin-Watson e tratada usando técnicas de modelagem de séries temporais.\n",
    "\n",
    "3. **Heteroscedasticidade**: A heteroscedasticidade ocorre quando a variância dos erros não é constante. Pode ser visualizada em um gráfico de resíduos versus valores ajustados e tratada transformando a variável dependente ou usando técnicas de modelagem mais robustas.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
